{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGdKypV4LXGtdyBsq4No2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NurhayatYurtaslan/Dogal-Dil-Isleme_NLP/blob/main/Tokenization%2C_Do%C4%9Fal_Dil_%C4%B0%C5%9Fleme%C2%A0(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctf8R3YqggT6",
        "outputId": "a8bbc11a-6abd-4d07-d34e-5d96b39442bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a sentence: Bu Python kodu, kullanıcıdan bir cümle girmesini isteyen bir programdır.\n",
            "['Bu', 'Python', 'kodu', ',', 'kullanıcıdan', 'bir', 'cümle', 'girmesini', 'isteyen', 'bir', 'programdır', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = input(\"Please enter a sentence: \")\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "text = input(\"Please enter a paragraph: \")\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "for sentence in sentences:\n",
        "    tokens = word_tokenize(sentence)\n",
        "    print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5wNttQ0gpYk",
        "outputId": "b0b8a77e-cfe3-4842-fca4-cfe4c2351422"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a paragraph: Bu kod, input() fonksiyonu aracılığıyla kullanıcıdan bir paragraf girmesini ister. Ardından, sent_tokenize() fonksiyonu kullanılarak paragraf cümlelere ayrılır. Daha sonra, her bir cümle word_tokenize() fonksiyonu kullanılarak kelimelere ayrılır ve sonuç ekrana yazdırılır.\n",
            "['Bu', 'kod', ',', 'input', '(', ')', 'fonksiyonu', 'aracılığıyla', 'kullanıcıdan', 'bir', 'paragraf', 'girmesini', 'ister', '.']\n",
            "['Ardından', ',', 'sent_tokenize', '(', ')', 'fonksiyonu', 'kullanılarak', 'paragraf', 'cümlelere', 'ayrılır', '.']\n",
            "['Daha', 'sonra', ',', 'her', 'bir', 'cümle', 'word_tokenize', '(', ')', 'fonksiyonu', 'kullanılarak', 'kelimelere', 'ayrılır', 've', 'sonuç', 'ekrana', 'yazdırılır', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PYvRsI8fgpHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "items = {}\n",
        "\n",
        "with open('/content/product_description.txt') as f:\n",
        "    for line in f:\n",
        "        # satırdaki kelime listesini oluştur\n",
        "        words = word_tokenize(line.strip())\n",
        "        # kelime ve fiyatı bir sözlüğe ekleyin\n",
        "        items[words[0]] = words[1]\n",
        "\n",
        "print(items)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "febZKchbgzWS",
        "outputId": "b089df40-d1ef-4761-e2d1-d5c2722f73ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'elbise': '100', 'ayakkabı': '80', 'çanta': '50', 'bluz': '70', 'etek': '60'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "with open('/content/example.txt', 'r') as file:\n",
        "    data = file.read().replace('\\n', ' ')\n",
        "\n",
        "tokens = word_tokenize(data)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Cm92lQg_aK",
        "outputId": "e66b98cd-39d7-4424-a306-0c1376365b70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'an', 'example', 'sentence', '.', 'It', 'contains', 'multiple', 'sentences', '.', 'Tokenization', 'will', 'split', 'it', 'into', 'separate', 'tokens', '.', 'Each', 'token', 'can', 'then', 'be', 'analyzed', 'individually', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "text = input(\"Enter a sentence: \")\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-OaQaAqkJo7",
        "outputId": "cac703cf-fd4c-4431-c815-66e1817822dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: Bu kod, TreebankWordTokenizer adlı bir sınıfın kullanımını gösteriyor. Bu sınıf, verilen bir metin örneğindeki cümleleri ve kelimeleri ayırmak için bir ağaç yapısı kullanır. Bu kodda öncelikle bir metin örneği tanımlanır ve daha sonra TreebankWordTokenizer sınıfı kullanılarak metin örneği cümle ve kelimelerine ayrılır. Sonuç olarak, ekranda, metindeki her bir kelime ayrı ayrı gösterilir.\n",
            "['Bu', 'kod', ',', 'TreebankWordTokenizer', 'adlı', 'bir', 'sınıfın', 'kullanımını', 'gösteriyor.', 'Bu', 'sınıf', ',', 'verilen', 'bir', 'metin', 'örneğindeki', 'cümleleri', 've', 'kelimeleri', 'ayırmak', 'için', 'bir', 'ağaç', 'yapısı', 'kullanır.', 'Bu', 'kodda', 'öncelikle', 'bir', 'metin', 'örneği', 'tanımlanır', 've', 'daha', 'sonra', 'TreebankWordTokenizer', 'sınıfı', 'kullanılarak', 'metin', 'örneği', 'cümle', 've', 'kelimelerine', 'ayrılır.', 'Sonuç', 'olarak', ',', 'ekranda', ',', 'metindeki', 'her', 'bir', 'kelime', 'ayrı', 'ayrı', 'gösterilir', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = input(\"Enter a sentence: \")\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "word_count = {}\n",
        "\n",
        "for token in tokens:\n",
        "    if token in word_count:\n",
        "        word_count[token] += 1\n",
        "    else:\n",
        "        word_count[token] = 1\n",
        "\n",
        "print(word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumJrqaLlN2C",
        "outputId": "9968b339-311d-4c4f-8116-95715477732b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: u kod örneğinde, öncelikle nltk kütüphanesini indiriyoruz ve word_tokenize yöntemini kullanarak text değişkenindeki metni kelime öbeklerine bölmek için bir tokenizasyon uyguluyoruz.  Daha sonra, bir word_count sözlüğü tanımlıyoruz ve her kelimenin sayısını bu sözlükte depoluyoruz. Bu, kelime öbeklerini tekrar saymak için bir döngü kullanıyoruz. Eğer kelime öbeği zaten word_count sözlüğünde varsa, o kelimenin sayısını bir artırıyoruz. Aksi takdirde, kelime öbeğini sözlüğe ekliyoruz ve sayısını bir yapıyoruz.  Son olarak, word_count sözlüğünü ekrana yazdırarak, metindeki her kelimenin kaç kez tekrar ettiğini görebilirsiniz.\n",
            "{'u': 1, 'kod': 1, 'örneğinde': 1, ',': 7, 'öncelikle': 1, 'nltk': 1, 'kütüphanesini': 1, 'indiriyoruz': 1, 've': 3, 'word_tokenize': 1, 'yöntemini': 1, 'kullanarak': 1, 'text': 1, 'değişkenindeki': 1, 'metni': 1, 'kelime': 4, 'öbeklerine': 1, 'bölmek': 1, 'için': 2, 'bir': 5, 'tokenizasyon': 1, 'uyguluyoruz': 1, '.': 6, 'Daha': 1, 'sonra': 1, 'word_count': 3, 'sözlüğü': 1, 'tanımlıyoruz': 1, 'her': 2, 'kelimenin': 3, 'sayısını': 3, 'bu': 1, 'sözlükte': 1, 'depoluyoruz': 1, 'Bu': 1, 'öbeklerini': 1, 'tekrar': 2, 'saymak': 1, 'döngü': 1, 'kullanıyoruz': 1, 'Eğer': 1, 'öbeği': 1, 'zaten': 1, 'sözlüğünde': 1, 'varsa': 1, 'o': 1, 'artırıyoruz': 1, 'Aksi': 1, 'takdirde': 1, 'öbeğini': 1, 'sözlüğe': 1, 'ekliyoruz': 1, 'yapıyoruz': 1, 'Son': 1, 'olarak': 1, 'sözlüğünü': 1, 'ekrana': 1, 'yazdırarak': 1, 'metindeki': 1, 'kaç': 1, 'kez': 1, 'ettiğini': 1, 'görebilirsiniz': 1}\n"
          ]
        }
      ]
    }
  ]
}