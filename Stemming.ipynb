{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAtU0grdwUOb22lwkatsgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NurhayatYurtaslan/Dogal-Dil-Isleme_NLP/blob/main/Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC_9w3nSDpMV",
        "outputId": "be24a4d4-d2a9-4182-8919-a8573c82e543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write\n",
            "write\n",
            "written\n",
            "write\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "words = [\"write\", \"writing\", \"written\", \"writes\"]\n",
        "\n",
        "for w in words:\n",
        "    print(ps.stem(w))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu örnekte, nltk kütüphanesi kullanılarak bir PorterStemmer nesnesi oluşturulmuştur. Ardından, word_tokenize() fonksiyonu kullanılarak bir liste oluşturulmuş ve her kelimeyi for döngüsü içinde ps.stem() fonksiyonuna göndererek kelime kökleri elde edilmiştir.\n",
        "\n",
        "Çıktı olarak, her kelimenin kökü ekrana yazdırılmıştır"
      ],
      "metadata": {
        "id": "JhZiIwqwDyCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "text = \"The quick brown fox jumped over the lazy dog's back.\"\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "for token in tokens:\n",
        "    print(stemmer.stem(token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM4vPOPSD2dc",
        "outputId": "cbb31307-2d62-4fc8-e520-b2b065ebf87d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\n",
            "quick\n",
            "brown\n",
            "fox\n",
            "jump\n",
            "over\n",
            "the\n",
            "lazi\n",
            "dog\n",
            "'s\n",
            "back\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, SnowballStemmer sınıfını kullanarak İngilizce kelimeleri köklerine ayırır. Öncelikle, nltk kütüphanesinden punkt paketini indiriyoruz. Daha sonra, örnek bir metin tanımlıyoruz ve word_tokenize fonksiyonunu kullanarak bu metni kelimelere ayırıyoruz. Son olarak, her kelime için stem işlemi yapıyoruz ve sonuçları yazdırıyoruz."
      ],
      "metadata": {
        "id": "93OKBhwOGpbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Metin\n",
        "text = \"I am loving this weather, it is so pleasant outside\"\n",
        "\n",
        "# Tokenize\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Stemming\n",
        "ps = PorterStemmer()\n",
        "stemmed_tokens = [ps.stem(token) for token in tokens]\n",
        "\n",
        "# Kelime köklerini yazdırma\n",
        "print(stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RciJpH1MGrzt",
        "outputId": "3f004809-5c28-410f-c4be-4f95d6c2c202"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'am', 'love', 'thi', 'weather', ',', 'it', 'is', 'so', 'pleasant', 'outsid']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabiki, burada öncelikle bir metnin tokenization işleminden geçirilmesi gerekiyor. Ardından stemming uygulanabilir. Aşağıdaki örnek, bir metnin kelime köklerini çıkarmak için hem stemming hem de tokenization kullanıyor, \"loving\" kelimesi \"love\" olarak, \"pleasant\" kelimesi \"pleas\" olarak kök haline getirilir."
      ],
      "metadata": {
        "id": "DNKO74FsHOnL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oemwXv40HS9U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}